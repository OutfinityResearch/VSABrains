{
  "id": "vsaindex",
  "title": "VSA as Index - Semantic Addressing",
  "narrations": {
    "en": "Up to now, the grid has been our address space: you write tokens at (x, y) and later you can return to that exact location. But sometimes you want the opposite: start from meaning and ask what in my memory is about this. This scene introduces that idea: VSA as an index.\n\nVector Symbolic Architectures (also called Hyperdimensional Computing) represent concepts as very high-dimensional vectors. In thousands of dimensions, random vectors are almost orthogonal. That gives us two useful properties: we can combine many items with limited interference, and we can measure similarity with a simple dot product or cosine.\n\nTwo core operations matter.\n\nFirst, bundling: add several concept vectors to get a single context vector. You can treat this as a soft set representation: the more often a feature appears, the more it influences the bundle.\n\nSecond, binding: combine a role with a value to make a structured relation. For example: subject = Alice, action = enters, location = kitchen. Binding keeps these roles distinct even when we later bundle everything together.\n\nIn VSABrains, VSA does not replace the grid. It points into it. We store a semantic key alongside each grid trajectory, then use semantic similarity to propose candidate locations quickly, before the exact, auditable grid match takes over.",
    "ro": "Până acum, grila a fost spațiul nostru de adrese: scrii token-uri la (x, y) și mai târziu poți reveni exact la acea locație. Dar uneori vrei inversul: pornești de la semnificație și întrebi ce din memoria mea este despre asta. Scena aceasta introduce ideea: VSA ca index.\n\nArhitecturile Simbolice Vectoriale (numite și Hyperdimensional Computing) reprezintă concepte ca vectori de dimensiuni foarte mari. În mii de dimensiuni, vectorii aleatori sunt aproape ortogonali. Asta ne oferă două proprietăți utile: putem combina multe elemente cu interferență limitată și putem măsura similaritatea cu un simplu produs scalar sau cosinus.\n\nDouă operații sunt esențiale.\n\nÎn primul rând, bundling: aduni mai mulți vectori de concepte într-un singur vector de context. Îl poți vedea ca pe o reprezentare de tip set moale: cu cât o trăsătură apare mai des, cu atât influențează mai mult bundle-ul.\n\nÎn al doilea rând, binding: combini un rol cu o valoare ca să obții o relație structurată. De exemplu: subiect = Alice, acțiune = intră, locație = bucătărie. Binding-ul ține rolurile separate chiar și atunci când le bundluim împreună.\n\nÎn VSABrains, VSA nu înlocuiește grila. O indexează. Stocăm o cheie semantică lângă fiecare traiectorie pe grilă, apoi folosim similaritatea semantică ca să propunem rapid locații candidate, înainte ca potrivirea exactă, auditabilă, pe grilă să preia controlul."
  },
  "keyIdeas": {
    "en": "VSA provides semantic hashing: similar content gets similar addresses.",
    "ro": "VSA oferă hashing semantic: conținut similar primește adrese similare."
  }
}
