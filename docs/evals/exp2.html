<div class="section">
  <h2>Experiment 2: Narrative Coherence</h2>
  <p>
    Goal: show that the system can track characters, objects, and locations over long stories
    without “forgetting” earlier facts. This includes coreference (pronouns), repeated motifs,
    and time localization by replay.
  </p>
  <p class="note">
    Plain-language version: we want the system to keep a consistent story memory even when
    the narrative is long and messy.
  </p>

  <h3>How this experiment works</h3>
  <ul>
    <li>Generate a long synthetic story with entities, locations, and repeated motifs.</li>
    <li>Insert pronouns (coreference) that must resolve to the correct entity.</li>
    <li>Ask state questions (e.g., “Where is Alice?” or “Who has the key?”).</li>
    <li>Verify contradictions (e.g., dead actors acting).</li>
  </ul>

  <h3>How to read the metrics</h3>
  <ul>
    <li><strong>State Accuracy</strong> = correct final state after replay.</li>
    <li><strong>Motif Handling</strong> = still recognizes repeated events in long context.</li>
    <li><strong>Coref Resolution</strong> = resolves pronouns to the right entity.</li>
    <li><strong>Time Localization</strong> = can find where a past event occurred.</li>
    <li><strong>Conflict Detection</strong> = detects explicit contradictions.</li>
  </ul>

  <table class="table">
    <thead>
      <tr>
        <th>Metric</th>
        <th>Value</th>
        <th>Target</th>
        <th>Status</th>
      </tr>
    </thead>
    <tbody>
      <tr><td>State Accuracy</td><td>1.00</td><td>&gt; 0.85</td><td><span class="status-pill status-pass">Pass</span></td></tr>
      <tr><td>Motif Handling</td><td>1.00</td><td>&gt; 0.75</td><td><span class="status-pill status-pass">Pass</span></td></tr>
      <tr><td>Coref Resolution</td><td>1.00</td><td>&gt; 0.90</td><td><span class="status-pill status-pass">Pass</span></td></tr>
      <tr><td>Time Localization</td><td>1.00</td><td>&gt; 0.80</td><td><span class="status-pill status-pass">Pass</span></td></tr>
      <tr><td>Conflict Detection</td><td>1.00</td><td>&gt; 0.90</td><td><span class="status-pill status-pass">Pass</span></td></tr>
    </tbody>
  </table>
  <p class="note">
    Time localization here is replay-based verification against the fast maps (not a separate learned
    time model).
  </p>
  <p>
    Interpretation: passing means the system can preserve long‑range narrative state
    and resolve pronouns reliably under this synthetic setup. It does <em>not</em>
    prove open‑domain story understanding; it proves that the discrete memory pipeline
    is stable over time.
  </p>
</div>
